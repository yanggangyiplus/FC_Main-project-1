"""
LangGraph ì›Œí¬í”Œë¡œìš° ì •ì˜
ì „ì²´ ë¸”ë¡œê·¸ ìƒì„± íŒŒì´í”„ë¼ì¸ì„ LangGraphë¡œ êµ¬í˜„
"""
from langgraph.graph import StateGraph, END
from typing import TypedDict, List, Dict, Any, Optional
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor
import time
import asyncio


def ensure_event_loop():
    """ThreadPoolExecutor ë‚´ì—ì„œ ì´ë²¤íŠ¸ ë£¨í”„ê°€ ì—†ì„ ë•Œ ìƒì„±"""
    try:
        asyncio.get_running_loop()
    except RuntimeError:
        # ì´ë²¤íŠ¸ ë£¨í”„ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent))

import importlib
# ìˆ«ìë¡œ ì‹œì‘í•˜ëŠ” ëª¨ë“ˆ ì´ë¦„ì€ ë™ì  import ì‚¬ìš©
NaverNewsScraper = importlib.import_module("modules.01_news_scraper").NaverNewsScraper
RAGBuilder = importlib.import_module("modules.02_rag_builder").RAGBuilder
BlogGenerator = importlib.import_module("modules.03_blog_generator").BlogGenerator
BlogCritic = importlib.import_module("modules.04_critic_qa").BlogCritic
Humanizer = importlib.import_module("modules.05_humanizer").Humanizer
ImageGenerator = importlib.import_module("modules.06_image_generator").ImageGenerator
NaverBlogPublisher = importlib.import_module("modules.07_blog_publisher").NaverBlogPublisher
SlackNotifier = importlib.import_module("modules.08_notifier").SlackNotifier
from config.settings import MAX_REGENERATION_ATTEMPTS, QUALITY_THRESHOLD
from config.logger import get_logger

logger = get_logger(__name__)


# ìƒíƒœ ì •ì˜
class BlogWorkflowState(TypedDict):
    category: str
    topic: str
    articles: List[Dict[str, Any]]
    context: str
    rag_context: str  # ğŸ¯ ì´ë¯¸ì§€ ìƒì„± ì‹œ RAG ì»¨í…ìŠ¤íŠ¸ í™œìš©
    blog_html: str
    evaluation: Optional[Dict[str, Any]]
    images: List[Dict[str, Any]]
    humanized_html: str
    final_html: str
    publish_result: Optional[Dict[str, Any]]
    regeneration_count: int
    start_time: float
    error: Optional[str]


def _paraphrase_title(original_title: str) -> str:
    """
    ë‰´ìŠ¤ ì œëª©ì„ ì•½ê°„ íŒ¨ëŸ¬í”„ë ˆì´ì¦ˆí•˜ì—¬ ì €ì‘ê¶Œ ë¬¸ì œ ë°©ì§€
    - ì›ë³¸ ì œëª©ì˜ í•µì‹¬ í‚¤ì›Œë“œëŠ” ìœ ì§€í•˜ë©´ì„œ í‘œí˜„ ë°©ì‹ ë³€ê²½
    - SEOì— ë¶ˆë¦¬í•˜ì§€ ì•Šì€ ìˆ˜ì¤€ì˜ ë³€í˜•
    """
    import re
    
    # ê¸°ë³¸ ë³€í˜• ê·œì¹™
    replacements = [
        # ë‰´ìŠ¤ ì œëª© íŠ¹ìœ ì˜ í‘œí˜„ ë³€í˜•
        (r"[â€¦â‹¯\.\.\.]+", "... "),
        (r"['']", "'"),
        (r'[""]', '"'),
        # ë”°ì˜´í‘œ ìŠ¤íƒ€ì¼ í†µì¼
        (r"'([^']+)'", r"'\1'"),
        # ë¶ˆí•„ìš”í•œ ê³µë°± ì •ë¦¬
        (r"\s+", " "),
    ]
    
    title = original_title.strip()
    for pattern, replacement in replacements:
        title = re.sub(pattern, replacement, title)
    
    # ì œëª©ì´ ë„ˆë¬´ ê¸¸ë©´ í•µì‹¬ë§Œ ìœ ì§€
    if len(title) > 50:
        # ì²« ë²ˆì§¸ êµ¬ë¶„ì(â€¦, -, |)ê¹Œì§€ë§Œ ì‚¬ìš©
        for sep in ['â€¦', '...', ' - ', ' | ', 'Â·']:
            if sep in title:
                parts = title.split(sep)
                if len(parts[0]) >= 15:  # ìµœì†Œ ê¸¸ì´ í™•ë³´
                    title = parts[0].strip() + " ê´€ë ¨ ì†Œì‹"
                    break
    
    # ì•½ê°„ì˜ í‘œí˜„ ë³€í˜• (í•µì‹¬ ì˜ë¯¸ëŠ” ìœ ì§€)
    # ìˆ«ì/ë‚ ì§œ í‘œí˜„ ìœ ì§€, íšŒì‚¬ëª…/ì¸ëª… ìœ ì§€
    # ë‹¨, "~í•œë‹¤" â†’ "~í•´" ë“±ì˜ ì–´ë¯¸ ë³€í˜•ì€ í•˜ì§€ ì•ŠìŒ (SEO ì˜í–¥)
    
    return title.strip()


# ë…¸ë“œ í•¨ìˆ˜ë“¤
def scrape_news_node(state: BlogWorkflowState) -> BlogWorkflowState:
    """1. ë‰´ìŠ¤ ìŠ¤í¬ë˜í•‘ ë…¸ë“œ"""
    logger.info(f"[Node] ë‰´ìŠ¤ ìŠ¤í¬ë˜í•‘ ì‹œì‘ (ì¹´í…Œê³ ë¦¬: {state['category']})")

    scraper = NaverNewsScraper(headless=True)
    try:
        # scrape_categoryëŠ” ScrapedData ê°ì²´ ë°˜í™˜ (topics ì•ˆì— articles ìˆìŒ)
        scraped_data = scraper.scrape_category(state['category'], top_n_topics=5, articles_per_topic=5)
        # ëª¨ë“  ì£¼ì œì˜ ê¸°ì‚¬ë“¤ì„ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ í•©ì¹¨
        articles = []
        for topic in scraped_data.topics:
            articles.extend(topic.articles)
        state['articles'] = [article.to_dict() for article in articles]
        logger.info(f"[Node] {len(articles)}ê°œ ê¸°ì‚¬ ìˆ˜ì§‘ ì™„ë£Œ")
        
        # ğŸ¯ SEO ìµœì í™”: ìŠ¤í¬ë˜í•‘ëœ ì²« ë²ˆì§¸ ì£¼ì œì˜ ì‹¤ì œ ì œëª©ì„ íŒ¨ëŸ¬í”„ë ˆì´ì¦ˆí•˜ì—¬ ì‚¬ìš©
        # ì €ì‘ê¶Œ ë¬¸ì œ ë°©ì§€ë¥¼ ìœ„í•´ ì•½ê°„ì˜ í‘œí˜„ ë³€í˜• ì ìš©
        if scraped_data.topics and len(scraped_data.topics) > 0:
            first_topic = scraped_data.topics[0]
            original_topic = state['topic']
            original_title = first_topic.topic_title
            paraphrased_title = _paraphrase_title(original_title)
            state['topic'] = paraphrased_title
            logger.info(f"[Node] SEO ì£¼ì œ ì—…ë°ì´íŠ¸: '{original_topic}' â†’ '{original_title}' â†’ '{paraphrased_title}' (íŒ¨ëŸ¬í”„ë ˆì´ì¦ˆ)")
    except Exception as e:
        logger.error(f"[Node] ë‰´ìŠ¤ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {e}")
        state['error'] = str(e)
    finally:
        scraper.close()

    return state


def build_rag_node(state: BlogWorkflowState) -> BlogWorkflowState:
    """2. RAG êµ¬ì¶• ë…¸ë“œ"""
    logger.info("[Node] RAG êµ¬ì¶• ì‹œì‘")

    try:
        rag = RAGBuilder()
        count = rag.add_articles(state['articles'], state['category'])
        logger.info(f"[Node] {count}ê°œ ê¸°ì‚¬ ë²¡í„°í™” ì™„ë£Œ")

        # ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        context = rag.get_context_for_topic(state['topic'], n_results=10)
        state['context'] = context
        state['rag_context'] = context  # ğŸ¯ ì´ë¯¸ì§€ ìƒì„± ì‹œ RAG ì»¨í…ìŠ¤íŠ¸ í™œìš©ì„ ìœ„í•´ ë³„ë„ ì €ì¥
        logger.info(f"[Node] ì»¨í…ìŠ¤íŠ¸ ìƒì„± ì™„ë£Œ (ê¸¸ì´: {len(context)})")
    except Exception as e:
        logger.error(f"[Node] RAG êµ¬ì¶• ì‹¤íŒ¨: {e}")
        state['error'] = str(e)

    return state


def generate_blog_node(state: BlogWorkflowState) -> BlogWorkflowState:
    """3. ë¸”ë¡œê·¸ ìƒì„± ë…¸ë“œ"""
    logger.info("[Node] ë¸”ë¡œê·¸ ìƒì„± ì‹œì‘")
    ensure_event_loop()  # ThreadPoolExecutor ë‚´ì—ì„œ ì´ë²¤íŠ¸ ë£¨í”„ ë³´ì¥

    try:
        generator = BlogGenerator()

        # í”¼ë“œë°±ì´ ìˆìœ¼ë©´ í¬í•¨
        previous_feedback = state['evaluation'] if state['regeneration_count'] > 0 else None

        html = generator.generate_blog(
            topic=state['topic'],
            context=state['context'],
            previous_feedback=previous_feedback
        )

        state['blog_html'] = html
        logger.info(f"[Node] ë¸”ë¡œê·¸ ìƒì„± ì™„ë£Œ (ì‹œë„: {state['regeneration_count'] + 1})")
    except Exception as e:
        logger.error(f"[Node] ë¸”ë¡œê·¸ ìƒì„± ì‹¤íŒ¨: {e}")
        state['error'] = str(e)

    return state


def evaluate_blog_node(state: BlogWorkflowState) -> BlogWorkflowState:
    """4. í’ˆì§ˆ í‰ê°€ ë…¸ë“œ"""
    logger.info("[Node] í’ˆì§ˆ í‰ê°€ ì‹œì‘")
    ensure_event_loop()  # ThreadPoolExecutor ë‚´ì—ì„œ ì´ë²¤íŠ¸ ë£¨í”„ ë³´ì¥

    try:
        critic = BlogCritic()
        evaluation = critic.evaluate(
            html=state['blog_html'],
            topic=state['topic'],
            context=state['context']
        )

        state['evaluation'] = evaluation
        logger.info(f"[Node] í‰ê°€ ì™„ë£Œ (ì ìˆ˜: {evaluation['score']}/100, í†µê³¼: {evaluation['passed']})")
    except Exception as e:
        logger.error(f"[Node] í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨: {e}")
        state['error'] = str(e)

    return state


def check_quality_node(state: BlogWorkflowState) -> str:
    """5. í’ˆì§ˆ ì²´í¬ ë…¸ë“œ (ë¶„ê¸° ê²°ì •)"""
    evaluation = state['evaluation']

    if evaluation['passed']:
        logger.info("[Node] í’ˆì§ˆ í‰ê°€ í†µê³¼ â†’ ë³‘ë ¬ ì²˜ë¦¬")
        return "parallel_processing"
    elif state['regeneration_count'] < MAX_REGENERATION_ATTEMPTS - 1:
        state['regeneration_count'] += 1
        logger.info(f"[Node] í’ˆì§ˆ ë¯¸ë‹¬ â†’ ì¬ìƒì„± ({state['regeneration_count']}/{MAX_REGENERATION_ATTEMPTS})")
        return "regenerate"
    else:
        logger.error(f"[Node] ìµœëŒ€ ì¬ìƒì„± íšŸìˆ˜ ì´ˆê³¼ ({MAX_REGENERATION_ATTEMPTS}íšŒ) â†’ ë°œí–‰ ì‹¤íŒ¨")
        return "quality_fail"


def quality_fail_node(state: BlogWorkflowState) -> BlogWorkflowState:
    """í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨ë¡œ ì¸í•œ ë°œí–‰ ì¤‘ë‹¨ ë…¸ë“œ"""
    logger.error("[Node] í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨ë¡œ ë°œí–‰ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")

    state['publish_result'] = {
        "success": False,
        "error": f"í’ˆì§ˆ í‰ê°€ {MAX_REGENERATION_ATTEMPTS}íšŒ ì—°ì† ì‹¤íŒ¨ (ìµœì¢… ì ìˆ˜: {state['evaluation'].get('score', 'N/A')}/100)",
        "attempts": state['regeneration_count'] + 1,
        "url": None
    }
    state['error'] = "í’ˆì§ˆ ê¸°ì¤€ ë¯¸ë‹¬ë¡œ ë°œí–‰ ì¤‘ë‹¨"

    return state


def parallel_processing_node(state: BlogWorkflowState) -> BlogWorkflowState:
    """6. ë³‘ë ¬ ì²˜ë¦¬ ë…¸ë“œ (ì´ë¯¸ì§€ ìƒì„± + ì¸ê°„í™”)"""
    logger.info("[Node] ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘ (ì´ë¯¸ì§€ ìƒì„± + ì¸ê°„í™”)")

    def generate_images_task():
        ensure_event_loop()  # ThreadPoolExecutor ë‚´ì—ì„œ ì´ë²¤íŠ¸ ë£¨í”„ ë³´ì¥
        try:
            # ì¹´í…Œê³ ë¦¬ ì „ë‹¬í•˜ì—¬ í´ë” ë¶„ë¥˜
            img_gen = ImageGenerator(category=state['category'])
            blog_gen = BlogGenerator()
            placeholders = blog_gen.extract_image_placeholders(state['blog_html'])
            
            # ğŸ¯ ë¸”ë¡œê·¸ ë‚´ìš© + RAG ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ìƒì„±
            # RAG ì»¨í…ìŠ¤íŠ¸ì—ì„œ ë°°ê²½ ì •ë³´(íšŒì‚¬ëª…, ì¥ì†Œ, ì‚¬ê±´ ë“±)ë¥¼ ì¶”ì¶œí•˜ì—¬ ì´ë¯¸ì§€ ìƒì„±ì— í™œìš©
            images = img_gen.generate_images_for_blog(
                blog_topic=state['topic'],
                blog_content=state['blog_html'],
                count=len(placeholders) if placeholders else 3,
                rag_context=state.get('rag_context', '')  # RAG ì»¨í…ìŠ¤íŠ¸ ì „ë‹¬
            )
            return images
        except Exception as e:
            logger.error(f"ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}")
            return []

    def humanize_task():
        ensure_event_loop()  # ThreadPoolExecutor ë‚´ì—ì„œ ì´ë²¤íŠ¸ ë£¨í”„ ë³´ì¥
        try:
            humanizer = Humanizer()
            humanized = humanizer.humanize(state['blog_html'])
            return humanized
        except Exception as e:
            logger.error(f"ì¸ê°„í™” ì‹¤íŒ¨: {e}")
            return state['blog_html']  # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì‚¬ìš©

    # ë³‘ë ¬ ì‹¤í–‰
    with ThreadPoolExecutor(max_workers=2) as executor:
        future_images = executor.submit(generate_images_task)
        future_humanize = executor.submit(humanize_task)

        state['images'] = future_images.result()
        state['humanized_html'] = future_humanize.result()

    logger.info(f"[Node] ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ (ì´ë¯¸ì§€: {len(state['images'])}ê°œ)")
    return state


def publish_blog_node(state: BlogWorkflowState) -> BlogWorkflowState:
    """7. ë¸”ë¡œê·¸ ë°œí–‰ ë…¸ë“œ"""
    logger.info("[Node] ë¸”ë¡œê·¸ ë°œí–‰ ì‹œì‘")

    try:
        publisher = NaverBlogPublisher(headless=False)

        result = publisher.publish(
            html=state['humanized_html'],
            images=state['images'],
            title=state['topic']
        )

        state['publish_result'] = result
        state['final_html'] = publisher.assemble_html_with_images(
            state['humanized_html'],
            state['images']
        )

        publisher.close()

        if result['success']:
            logger.info(f"[Node] ë°œí–‰ ì„±ê³µ: {result['url']}")
        else:
            logger.error(f"[Node] ë°œí–‰ ì‹¤íŒ¨: {result['error']}")

    except Exception as e:
        logger.error(f"[Node] ë°œí–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        state['error'] = str(e)
        state['publish_result'] = {
            "success": False,
            "error": str(e),
            "attempts": 0
        }

    return state


def notify_node(state: BlogWorkflowState) -> BlogWorkflowState:
    """8. ì•Œë¦¼ ë…¸ë“œ"""
    logger.info("[Node] ì•Œë¦¼ ì „ì†¡ ì‹œì‘")

    try:
        notifier = SlackNotifier()
        duration = int(time.time() - state['start_time'])

        if state['publish_result']['success']:
            notifier.send_success_notification(
                topic=state['topic'],
                category=state['category'],
                blog_url=state['publish_result']['url'],
                attempts=state['publish_result']['attempts'],
                duration_seconds=duration
            )
        else:
            notifier.send_failure_notification(
                topic=state['topic'],
                category=state['category'],
                error=state['publish_result']['error'],
                attempts=state['publish_result']['attempts'],
                duration_seconds=duration
            )

        logger.info("[Node] ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"[Node] ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {e}")

    return state


# ì›Œí¬í”Œë¡œìš° ìƒì„±
def create_blog_workflow() -> StateGraph:
    """ë¸”ë¡œê·¸ ìƒì„± ì›Œí¬í”Œë¡œìš° ìƒì„±"""

    workflow = StateGraph(BlogWorkflowState)

    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("scrape_news", scrape_news_node)
    workflow.add_node("build_rag", build_rag_node)
    workflow.add_node("generate_blog", generate_blog_node)
    workflow.add_node("evaluate_blog", evaluate_blog_node)
    workflow.add_node("quality_fail", quality_fail_node)  # í’ˆì§ˆ ì‹¤íŒ¨ ë…¸ë“œ
    workflow.add_node("parallel_processing", parallel_processing_node)
    workflow.add_node("publish_blog", publish_blog_node)
    workflow.add_node("notify", notify_node)

    # ì—£ì§€ ì¶”ê°€
    workflow.set_entry_point("scrape_news")
    workflow.add_edge("scrape_news", "build_rag")
    workflow.add_edge("build_rag", "generate_blog")
    workflow.add_edge("generate_blog", "evaluate_blog")

    # ì¡°ê±´ë¶€ ì—£ì§€ (í’ˆì§ˆ ì²´í¬)
    workflow.add_conditional_edges(
        "evaluate_blog",
        check_quality_node,
        {
            "regenerate": "generate_blog",
            "parallel_processing": "parallel_processing",
            "quality_fail": "quality_fail"  # 3íšŒ ì‹¤íŒ¨ ì‹œ ë°œí–‰ ì¤‘ë‹¨
        }
    )

    workflow.add_edge("quality_fail", "notify")  # ì‹¤íŒ¨ ì‹œ ì•Œë¦¼ë§Œ ë³´ë‚´ê³  ì¢…ë£Œ
    workflow.add_edge("parallel_processing", "publish_blog")
    workflow.add_edge("publish_blog", "notify")
    workflow.add_edge("notify", END)

    return workflow.compile()


def run_workflow(category: str, topic: str) -> Dict[str, Any]:
    """
    ì›Œí¬í”Œë¡œìš° ì‹¤í–‰

    Args:
        category: ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬
        topic: ë¸”ë¡œê·¸ ì£¼ì œ

    Returns:
        ìµœì¢… ìƒíƒœ
    """
    logger.info(f"=== ì›Œí¬í”Œë¡œìš° ì‹œì‘ (ì¹´í…Œê³ ë¦¬: {category}, ì£¼ì œ: {topic}) ===")

    # ì´ˆê¸° ìƒíƒœ
    initial_state: BlogWorkflowState = {
        "category": category,
        "topic": topic,
        "articles": [],
        "context": "",
        "rag_context": "",  # ğŸ¯ ì´ë¯¸ì§€ ìƒì„± ì‹œ RAG ì»¨í…ìŠ¤íŠ¸ í™œìš©
        "blog_html": "",
        "evaluation": None,
        "images": [],
        "humanized_html": "",
        "final_html": "",
        "publish_result": None,
        "regeneration_count": 0,
        "start_time": time.time(),
        "error": None
    }

    # ì›Œí¬í”Œë¡œìš° ìƒì„± ë° ì‹¤í–‰
    workflow = create_blog_workflow()
    final_state = workflow.invoke(initial_state)

    duration = int(time.time() - initial_state['start_time'])
    logger.info(f"=== ì›Œí¬í”Œë¡œìš° ì™„ë£Œ (ì†Œìš” ì‹œê°„: {duration}ì´ˆ) ===")

    return final_state


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    result = run_workflow(
        category="it_technology",
        topic="ìµœì‹  AI ê¸°ìˆ  íŠ¸ë Œë“œ"
    )

    print("\n=== ìµœì¢… ê²°ê³¼ ===")
    print(f"ë°œí–‰ ì„±ê³µ: {result['publish_result']['success']}")
    if result['publish_result']['success']:
        print(f"URL: {result['publish_result']['url']}")
    else:
        print(f"ì˜¤ë¥˜: {result['publish_result']['error']}")
