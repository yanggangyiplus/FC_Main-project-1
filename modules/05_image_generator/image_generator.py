"""
ì´ë¯¸ì§€ ìƒì„±ê¸° - Hugging Face (ë¬´ë£Œ), DALL-E, Stable Diffusion, Z-Image-Turbo ì§€ì›
"""
from openai import OpenAI
from typing import List, Dict, Any, Optional
from pathlib import Path
import requests
from datetime import datetime
from io import BytesIO
import pickle
import os
import time

# êµ¬ê¸€ ë“œë¼ì´ë¸Œ ê´€ë ¨ import (ì„ íƒì )
GOOGLE_DRIVE_AVAILABLE = False
try:
    from google.oauth2.credentials import Credentials
    from google_auth_oauthlib.flow import InstalledAppFlow
    from google.auth.transport.requests import Request as GoogleRequest
    from googleapiclient.discovery import build
    from googleapiclient.http import MediaIoBaseUpload
    GOOGLE_DRIVE_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ êµ¬ê¸€ ë“œë¼ì´ë¸Œ íŒ¨í‚¤ì§€ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    print("   ë¡œì»¬ ì €ì¥ ê¸°ëŠ¥ë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.")

# Z-Image-Turbo ë¡œì»¬ ì‹¤í–‰ ê´€ë ¨ import (ì„ íƒì )
Z_IMAGE_AVAILABLE = False
try:
    import torch
    from diffusers import ZImagePipeline
    Z_IMAGE_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ Z-Image-Turbo íŒ¨í‚¤ì§€ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    print("   Z-Image-Turbo ë¡œì»¬ ì‹¤í–‰ì„ ì‚¬ìš©í•˜ë ¤ë©´ ë‹¤ìŒì„ ì„¤ì¹˜í•˜ì„¸ìš”:")
    print("   pip install git+https://github.com/huggingface/diffusers")
    print("   pip install torch torchvision")

import sys
sys.path.append(str(Path(__file__).parent.parent.parent))
from config.settings import (
    OPENAI_API_KEY, IMAGES_DIR, IMAGE_MODEL, IMAGE_SIZE,
    GOOGLE_DRIVE_CREDENTIALS_PATH, GOOGLE_DRIVE_FOLDER_ID,
    HUGGINGFACE_API_KEY, HUGGINGFACE_MODEL, Z_IMAGE_CPU_OFFLOAD
)
from config.logger import get_logger

logger = get_logger(__name__)


class ImageGenerator:
    """ì´ë¯¸ì§€ ìƒì„± ë° ì €ì¥ í´ë˜ìŠ¤"""

    def __init__(self, model: str = IMAGE_MODEL, use_google_drive: bool = True, image_size: str = IMAGE_SIZE, category: str = ""):
        """
        Args:
            model: ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ 
                - "huggingface" (ë¬´ë£Œ, ê¸°ë³¸ - Inference API)
                - "z-image-turbo" (ë¡œì»¬ ì‹¤í–‰, GPU í•„ìš”)
                - "dall-e-3" (ìœ ë£Œ)
                - "stable-diffusion-webui" (ë¡œì»¬)
            use_google_drive: êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì €ì¥ ì—¬ë¶€
            image_size: ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆ (ì˜ˆ: "1024x1024", "512x512")
            category: ì¹´í…Œê³ ë¦¬ (í´ë” êµ¬ë¶„ìš©, ì˜ˆ: "politics", "economy", "it_science")
        """
        self.model = model
        self.use_google_drive = use_google_drive
        self.image_size = image_size
        self.category = category  # ì¹´í…Œê³ ë¦¬ ì €ì¥
        self.drive_service = None
        self.client = None  # OpenAI ë˜ëŠ” Hugging Face í´ë¼ì´ì–¸íŠ¸
        self.z_image_pipe = None  # Z-Image-Turbo íŒŒì´í”„ë¼ì¸

        # ëª¨ë¸ë³„ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        if "z-image" in model.lower() or "tongyi" in HUGGINGFACE_MODEL.lower():
            # Z-Image-Turbo ë¡œì»¬ ì‹¤í–‰
            if not Z_IMAGE_AVAILABLE:
                raise ImportError(
                    "Z-Image-Turboë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ë‹¤ìŒ íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤:\n"
                    "pip install git+https://github.com/huggingface/diffusers\n"
                    "pip install torch torchvision"
                )
            self._init_z_image_turbo()
            logger.info("Z-Image-Turbo ë¡œì»¬ ì‹¤í–‰ ëª¨ë“œ ì‚¬ìš©")
            
        elif "huggingface" in model.lower():
            # Hugging Face Inference API (ë¬´ë£Œ)
            # Z-Image-Turbo ëª¨ë¸ì´ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ ë¡œì»¬ ì‹¤í–‰ìœ¼ë¡œ ì „í™˜
            if "z-image" in HUGGINGFACE_MODEL.lower() or "tongyi" in HUGGINGFACE_MODEL.lower():
                if not Z_IMAGE_AVAILABLE:
                    raise ImportError(
                        "Z-Image-Turboë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ë‹¤ìŒ íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤:\n"
                        "pip install git+https://github.com/huggingface/diffusers\n"
                        "pip install torch torchvision"
                    )
                self._init_z_image_turbo()
                logger.info("Z-Image-Turbo ë¡œì»¬ ì‹¤í–‰ ëª¨ë“œ ì‚¬ìš© (ìë™ ì „í™˜)")
            else:
                self.hf_api_url = f"https://api-inference.huggingface.co/models/{HUGGINGFACE_MODEL}"
                self.hf_headers = {}
                if HUGGINGFACE_API_KEY:
                    self.hf_headers["Authorization"] = f"Bearer {HUGGINGFACE_API_KEY}"
                logger.info(f"Hugging Face Inference API ëª¨ë¸ ì‚¬ìš©: {HUGGINGFACE_MODEL}")
            
        elif "dall-e" in model.lower():
            # OpenAI DALL-E (ìœ ë£Œ)
            if not OPENAI_API_KEY:
                raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            self.client = OpenAI(api_key=OPENAI_API_KEY)
            logger.info("DALL-E 3 ëª¨ë¸ ì‚¬ìš©")

        # êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì´ˆê¸°í™”
        if use_google_drive:
            self._init_google_drive()

        logger.info(f"ImageGenerator ì´ˆê¸°í™” (ëª¨ë¸: {model}, ì‚¬ì´ì¦ˆ: {image_size}, êµ¬ê¸€ ë“œë¼ì´ë¸Œ: {use_google_drive})")

    def _init_google_drive(self):
        """êµ¬ê¸€ ë“œë¼ì´ë¸Œ API ì´ˆê¸°í™”"""
        # êµ¬ê¸€ ë“œë¼ì´ë¸Œ íŒ¨í‚¤ì§€ê°€ ì—†ìœ¼ë©´ ë¡œì»¬ ì €ì¥ë§Œ ì‚¬ìš©
        if not GOOGLE_DRIVE_AVAILABLE:
            logger.warning("êµ¬ê¸€ ë“œë¼ì´ë¸Œ íŒ¨í‚¤ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. ë¡œì»¬ ì €ì¥ë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.")
            self.use_google_drive = False
            return
        
        SCOPES = ['https://www.googleapis.com/auth/drive.file']
        creds = None

        # í† í° íŒŒì¼ í™•ì¸
        token_path = Path(__file__).parent.parent.parent / "config" / "token.pickle"
        if token_path.exists():
            with open(token_path, 'rb') as token:
                creds = pickle.load(token)

        # í† í°ì´ ì—†ê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•Šìœ¼ë©´ ìƒˆë¡œ ìƒì„±
        if not creds or not creds.valid:
            if creds and creds.expired and creds.refresh_token:
                creds.refresh(GoogleRequest())
            else:
                if not Path(GOOGLE_DRIVE_CREDENTIALS_PATH).exists():
                    logger.warning(f"êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì¸ì¦ íŒŒì¼ ì—†ìŒ: {GOOGLE_DRIVE_CREDENTIALS_PATH}")
                    logger.warning("ë¡œì»¬ ì €ì¥ë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.")
                    self.use_google_drive = False
                    return

                flow = InstalledAppFlow.from_client_secrets_file(
                    GOOGLE_DRIVE_CREDENTIALS_PATH, SCOPES
                )
                creds = flow.run_local_server(port=0)

            # í† í° ì €ì¥
            with open(token_path, 'wb') as token:
                pickle.dump(creds, token)

        self.drive_service = build('drive', 'v3', credentials=creds)
        logger.info("êµ¬ê¸€ ë“œë¼ì´ë¸Œ API ì´ˆê¸°í™” ì™„ë£Œ")

    def _init_z_image_turbo(self):
        """Z-Image-Turbo íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”"""
        if not Z_IMAGE_AVAILABLE:
            raise ImportError("Z-Image-Turbo íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        try:
            # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
            device = "cuda" if torch.cuda.is_available() else "cpu"
            if device == "cpu":
                logger.warning("âš ï¸ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤ (ë§¤ìš° ëŠë¦¼).")
            
            # Z-Image-Turbo íŒŒì´í”„ë¼ì¸ ë¡œë“œ
            logger.info(f"Z-Image-Turbo ëª¨ë¸ ë¡œë”© ì¤‘... (ì¥ì¹˜: {device})")
            self.z_image_pipe = ZImagePipeline.from_pretrained(
                HUGGINGFACE_MODEL,
                torch_dtype=torch.bfloat16 if device == "cuda" else torch.float32,
                low_cpu_mem_usage=False,
            )
            self.z_image_pipe.to(device)
            
            # CPU ì˜¤í”„ë¡œë”© ì˜µì…˜ (ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•œ ê²½ìš°)
            # accelerate ë²„ì „ ì²´í¬ í•„ìš” (v0.17.0 ì´ìƒ)
            if device == "cpu" or Z_IMAGE_CPU_OFFLOAD:
                try:
                    import accelerate
                    from packaging import version
                    # accelerate ë²„ì „ í™•ì¸
                    accelerate_version = accelerate.__version__
                    if version.parse(accelerate_version) < version.parse("0.17.0"):
                        logger.warning(
                            f"âš ï¸ accelerate ë²„ì „ì´ ë‚®ìŠµë‹ˆë‹¤ (í˜„ì¬: {accelerate_version}, í•„ìš”: >=0.17.0). "
                            "CPU ì˜¤í”„ë¡œë”©ì„ ê±´ë„ˆëœë‹ˆë‹¤. "
                            "ì—…ê·¸ë ˆì´ë“œ: pip install accelerate>=0.17.0"
                        )
                    else:
                        self.z_image_pipe.enable_model_cpu_offload()
                        logger.info("CPU ì˜¤í”„ë¡œë”© í™œì„±í™”")
                except ImportError:
                    logger.warning(
                        "âš ï¸ accelerate íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
                        "CPU ì˜¤í”„ë¡œë”©ì„ ì‚¬ìš©í•˜ë ¤ë©´ ì„¤ì¹˜í•˜ì„¸ìš”: pip install accelerate>=0.17.0"
                    )
                except Exception as e:
                    logger.warning(f"âš ï¸ CPU ì˜¤í”„ë¡œë”© í™œì„±í™” ì‹¤íŒ¨: {e}. ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
            
            logger.info("âœ… Z-Image-Turbo íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"Z-Image-Turbo ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise Exception(f"Z-Image-Turbo ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    def generate_images(self, placeholders: List[Dict[str, Any]], category: str = None) -> List[Dict[str, Any]]:
        """
        ì´ë¯¸ì§€ í”Œë ˆì´ìŠ¤í™€ë” ë¦¬ìŠ¤íŠ¸ì— ëŒ€í•œ ì´ë¯¸ì§€ ìƒì„±

        Args:
            placeholders: í”Œë ˆì´ìŠ¤í™€ë” ì •ë³´ ë¦¬ìŠ¤íŠ¸
                [{"index": 0, "alt": "ì„¤ëª…", "tag": "<img...>"}, ...]
            category: ì¹´í…Œê³ ë¦¬ (Noneì´ë©´ self.category ì‚¬ìš©)

        Returns:
            ìƒì„±ëœ ì´ë¯¸ì§€ ì •ë³´ ë¦¬ìŠ¤íŠ¸
                [{"index": 0, "alt": "ì„¤ëª…", "local_path": "...", "url": "..."}, ...]
        """
        # ì¹´í…Œê³ ë¦¬ ì„¤ì • (íŒŒë¼ë¯¸í„° ìš°ì„ , ì—†ìœ¼ë©´ ì¸ìŠ¤í„´ìŠ¤ ì†ì„± ì‚¬ìš©)
        if category is not None:
            self.category = category
        
        logger.info(f"ì´ {len(placeholders)}ê°œ ì´ë¯¸ì§€ ìƒì„± ì‹œì‘ (ì¹´í…Œê³ ë¦¬: {self.category or 'ì—†ìŒ'})")

        results = []
        for placeholder in placeholders:
            try:
                result = self.generate_single_image(
                    prompt=placeholder['alt'],
                    index=placeholder['index']
                )
                results.append(result)
                logger.info(f"ì´ë¯¸ì§€ {placeholder['index'] + 1}/{len(placeholders)} ìƒì„± ì™„ë£Œ")

            except Exception as e:
                logger.error(f"ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨ (ì¸ë±ìŠ¤ {placeholder['index']}): {e}")
                results.append({
                    "index": placeholder['index'],
                    "alt": placeholder['alt'],
                    "local_path": None,
                    "url": None,
                    "error": str(e)
                })

        logger.info(f"ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ: ì„±ê³µ {len([r for r in results if r.get('url')])}ê°œ")
        return results

    def generate_single_image(self, prompt: str, index: int) -> Dict[str, Any]:
        """
        ë‹¨ì¼ ì´ë¯¸ì§€ ìƒì„±

        Args:
            prompt: ì´ë¯¸ì§€ ì„¤ëª… (alt í…ìŠ¤íŠ¸)
            index: ì´ë¯¸ì§€ ìˆœì„œ

        Returns:
            ì´ë¯¸ì§€ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        # alt í…ìŠ¤íŠ¸ì—ì„œ "[ì´ë¯¸ì§€ ì„¤ëª…: " ë¶€ë¶„ ì œê±°
        clean_prompt = prompt.replace("[ì´ë¯¸ì§€ ì„¤ëª…:", "").replace("]", "").strip()

        logger.info(f"ì´ë¯¸ì§€ ìƒì„± ì¤‘: '{clean_prompt[:50]}...'")

        # Z-Image-Turbo ë¡œì»¬ ì‹¤í–‰
        if self.z_image_pipe is not None:
            return self._generate_with_z_image_turbo(clean_prompt, index)
        elif "huggingface" in self.model.lower():
            return self._generate_with_huggingface(clean_prompt, index)
        elif "dall-e" in self.model.lower():
            return self._generate_with_dalle(clean_prompt, index)
        else:
            raise NotImplementedError(f"ëª¨ë¸ '{self.model}'ì€ ì•„ì§ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    def _generate_with_z_image_turbo(self, prompt: str, index: int) -> Dict[str, Any]:
        """
        Z-Image-Turboë¡œ ì´ë¯¸ì§€ ìƒì„± (ë¡œì»¬ ì‹¤í–‰)
        
        Args:
            prompt: í”„ë¡¬í”„íŠ¸ (ì˜ì–´, í•œêµ­ì–´, ì¤‘êµ­ì–´ ëª¨ë‘ ì§€ì›)
            index: ì¸ë±ìŠ¤
        
        Returns:
            ì´ë¯¸ì§€ ì •ë³´
        """
        if self.z_image_pipe is None:
            raise ValueError("Z-Image-Turbo íŒŒì´í”„ë¼ì¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        try:
            # ì´ë¯¸ì§€ í¬ê¸° íŒŒì‹± (ì˜ˆ: "1024x1024" -> (1024, 1024))
            width, height = map(int, self.image_size.split('x'))
            
            # Z-Image-Turbo ì´ë¯¸ì§€ ìƒì„±
            # num_inference_steps=9ëŠ” ì‹¤ì œë¡œ 8 NFE (Number of Function Evaluations)
            # guidance_scale=0.0 (Turbo ëª¨ë¸ì€ guidanceë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
            logger.info(f"Z-Image-Turbo ì´ë¯¸ì§€ ìƒì„± ì¤‘... (í¬ê¸°: {width}x{height})")
            
            device = "cuda" if torch.cuda.is_available() else "cpu"
            generator = torch.Generator(device).manual_seed(int(time.time()) % 2**32)
            
            image = self.z_image_pipe(
                prompt=prompt,
                height=height,
                width=width,
                num_inference_steps=9,  # 8 NFE
                guidance_scale=0.0,  # Turbo ëª¨ë¸ì€ guidance ì‚¬ìš© ì•ˆ í•¨
                generator=generator,
            ).images[0]
            
            # ì´ë¯¸ì§€ë¥¼ ë°”ì´íŠ¸ë¡œ ë³€í™˜
            from io import BytesIO
            image_bytes = BytesIO()
            image.save(image_bytes, format='PNG')
            image_data = image_bytes.getvalue()
            
            # ë¡œì»¬ ì €ì¥
            local_path = self._save_image_locally(image_data, index)
            
            # êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì—…ë¡œë“œ
            drive_url = None
            if self.use_google_drive and self.drive_service:
                drive_url = self._upload_to_google_drive(image_data, index, prompt)
            
            logger.info(f"âœ… Z-Image-Turbo ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ: {local_path}")
            
            return {
                "index": index,
                "alt": prompt,
                "local_path": str(local_path),
                "url": drive_url or str(local_path),
                "model": "z-image-turbo",
                "device": device
            }
            
        except Exception as e:
            logger.error(f"Z-Image-Turbo ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}")
            raise Exception(f"Z-Image-Turbo ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}")

    def _generate_with_dalle(self, prompt: str, index: int) -> Dict[str, Any]:
        """
        DALL-Eë¡œ ì´ë¯¸ì§€ ìƒì„±

        Args:
            prompt: í”„ë¡¬í”„íŠ¸
            index: ì¸ë±ìŠ¤

        Returns:
            ì´ë¯¸ì§€ ì •ë³´
        """
        # DALL-E í˜¸ì¶œ
        # DALL-E 3ëŠ” íŠ¹ì • ì‚¬ì´ì¦ˆë§Œ ì§€ì›: "1024x1024", "1024x1792", "1792x1024"
        dalle_size = self.image_size
        # ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‚¬ì´ì¦ˆë©´ 1024x1024ë¡œ ë³€ê²½
        if dalle_size not in ["1024x1024", "1024x1792", "1792x1024"]:
            logger.warning(f"DALL-E 3ê°€ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‚¬ì´ì¦ˆ {dalle_size}ë¥¼ 1024x1024ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.")
            dalle_size = "1024x1024"
        
        response = self.client.images.generate(
            model=self.model,
            prompt=prompt,
            size=dalle_size,
            quality="standard",  # or "hd"
            n=1
        )

        # ì´ë¯¸ì§€ URL ê°€ì ¸ì˜¤ê¸°
        image_url = response.data[0].url

        # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        image_data = requests.get(image_url).content

        # ë¡œì»¬ ì €ì¥
        local_path = self._save_image_locally(image_data, index)

        # êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì—…ë¡œë“œ
        drive_url = None
        if self.use_google_drive and self.drive_service:
            drive_url = self._upload_to_google_drive(image_data, index, prompt)

        return {
            "index": index,
            "alt": prompt,
            "local_path": str(local_path),
            "url": drive_url or str(local_path),  # ë“œë¼ì´ë¸Œ URL ìš°ì„ , ì—†ìœ¼ë©´ ë¡œì»¬ ê²½ë¡œ
            "original_dalle_url": image_url
        }

    def _generate_with_huggingface(self, prompt: str, index: int) -> Dict[str, Any]:
        """
        Hugging Face Inference APIë¡œ ì´ë¯¸ì§€ ìƒì„± (ë¬´ë£Œ)
        
        Args:
            prompt: í”„ë¡¬í”„íŠ¸
            index: ì¸ë±ìŠ¤
        
        Returns:
            ì´ë¯¸ì§€ ì •ë³´
        """
        # Z-Image-TurboëŠ” ì˜ì–´, í•œêµ­ì–´, ì¤‘êµ­ì–´ë¥¼ ëª¨ë‘ ì§€ì›í•˜ë¯€ë¡œ ì–´ë–¤ ì–¸ì–´ë“  ê·¸ëŒ€ë¡œ ì‚¬ìš© ê°€ëŠ¥
        # ëª¨ë¸ì— ë”°ë¼ í”„ë¡¬í”„íŠ¸ ê°œì„ 
        if "z-image" in HUGGINGFACE_MODEL.lower() or "tongyi" in HUGGINGFACE_MODEL.lower():
            # Z-Image-TurboëŠ” ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ìƒì„±ì— ìµœì í™”ë˜ì–´ ìˆìŒ
            # ì˜ì–´, í•œêµ­ì–´, ì¤‘êµ­ì–´ í”„ë¡¬í”„íŠ¸ ëª¨ë‘ ì§€ì›
            enhanced_prompt = f"{prompt}, high quality, detailed, professional"
        else:
            # Stable Diffusion ëª¨ë¸ìš© í”„ë¡¬í”„íŠ¸ ê°œì„  (ì£¼ë¡œ ì˜ì–´ì— ìµœì í™”)
            enhanced_prompt = f"{prompt}, high quality, detailed, 4k"
        
        # Hugging Face Inference API í˜¸ì¶œ
        # ì°¸ê³ : Hugging Face Inference APIëŠ” ëª¨ë¸ì— ë”°ë¼ ì‚¬ì´ì¦ˆê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        # ì¼ë¶€ ëª¨ë¸ì€ íŒŒë¼ë¯¸í„°ë¡œ ì‚¬ì´ì¦ˆë¥¼ ë°›ì„ ìˆ˜ ìˆì§€ë§Œ, ëŒ€ë¶€ë¶„ì€ ëª¨ë¸ ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
        payload = {"inputs": enhanced_prompt}
        logger.info(f"ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆ ìš”ì²­: {self.image_size} (ëª¨ë¸ ê¸°ë³¸ê°’ ì‚¬ìš© ê°€ëŠ¥)")
        
        max_retries = 3
        for attempt in range(max_retries):
            try:
                logger.info(f"Hugging Face API í˜¸ì¶œ ì¤‘... (ì‹œë„ {attempt + 1}/{max_retries})")
                response = requests.post(
                    self.hf_api_url,
                    headers=self.hf_headers,
                    json=payload,
                    timeout=60  # 60ì´ˆ íƒ€ì„ì•„ì›ƒ
                )
                
                # 410 Gone ì—ëŸ¬ ì²˜ë¦¬ (ëª¨ë¸ì´ ë” ì´ìƒ ì‚¬ìš© ë¶ˆê°€ëŠ¥ ë˜ëŠ” Inference API ë¯¸ì§€ì›)
                if response.status_code == 410:
                    # Z-Image-TurboëŠ” Inference APIë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŒ
                    if "z-image" in HUGGINGFACE_MODEL.lower() or "tongyi" in HUGGINGFACE_MODEL.lower():
                        error_message = (
                            f"âŒ ëª¨ë¸ '{HUGGINGFACE_MODEL}'ì€ Hugging Face Inference APIë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n\n"
                            f"ğŸ“Œ ì´ìœ : Z-Image-TurboëŠ” ë¡œì»¬ ì‹¤í–‰ ì „ìš© ëª¨ë¸ì…ë‹ˆë‹¤ (diffusers ë¼ì´ë¸ŒëŸ¬ë¦¬ í•„ìš”).\n\n"
                            f"ğŸ’¡ í•´ê²° ë°©ë²•:\n"
                            f"1. .env íŒŒì¼ì—ì„œ Inference API ì§€ì› ëª¨ë¸ë¡œ ë³€ê²½:\n"
                            f"   HUGGINGFACE_MODEL=runwayml/stable-diffusion-v1-5\n"
                            f"   ë˜ëŠ”\n"
                            f"   HUGGINGFACE_MODEL=stabilityai/stable-diffusion-2-1\n\n"
                            f"2. ë˜ëŠ” DALL-E 3 ì‚¬ìš© (ìœ ë£Œ, ë” ì•ˆì •ì ):\n"
                            f"   IMAGE_MODEL=dall-e-3\n"
                            f"   OPENAI_API_KEY=your-key-here\n\n"
                            f"3. Z-Image-Turbo ë¡œì»¬ ì‹¤í–‰ (ê³ ê¸‰, GPU í•„ìš”):\n"
                            f"   - diffusers ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ í•„ìš”\n"
                            f"   - NVIDIA GPU í•„ìš” (CUDA)\n"
                            f"   - ë³„ë„ êµ¬í˜„ í•„ìš”"
                        )
                    else:
                        error_message = (
                            f"âŒ ëª¨ë¸ '{HUGGINGFACE_MODEL}'ì´ ë” ì´ìƒ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (410 Gone).\n\n"
                            f"ğŸ’¡ í•´ê²° ë°©ë²•:\n"
                            f"1. .env íŒŒì¼ì—ì„œ ë‹¤ë¥¸ ëª¨ë¸ë¡œ ë³€ê²½:\n"
                            f"   HUGGINGFACE_MODEL=runwayml/stable-diffusion-v1-5\n"
                            f"   ë˜ëŠ”\n"
                            f"   HUGGINGFACE_MODEL=stabilityai/stable-diffusion-2-1\n\n"
                            f"2. ë˜ëŠ” DALL-E 3 ì‚¬ìš© (ìœ ë£Œ, ë” ì•ˆì •ì ):\n"
                            f"   IMAGE_MODEL=dall-e-3\n"
                            f"   OPENAI_API_KEY=your-key-here"
                        )
                    raise Exception(error_message)
                
                # ëª¨ë¸ ë¡œë”© ì¤‘ì¸ ê²½ìš° (503 ì—ëŸ¬)
                if response.status_code == 503:
                    error_data = response.json()
                    if "estimated_time" in error_data:
                        wait_time = min(error_data["estimated_time"], 30)  # ìµœëŒ€ 30ì´ˆ ëŒ€ê¸°
                        logger.info(f"ëª¨ë¸ ë¡œë”© ì¤‘... {wait_time}ì´ˆ ëŒ€ê¸°")
                        time.sleep(wait_time)
                        continue
                
                # ì—ëŸ¬ í™•ì¸
                response.raise_for_status()
                
                # ì´ë¯¸ì§€ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                image_data = response.content
                
                # ë¡œì»¬ ì €ì¥
                local_path = self._save_image_locally(image_data, index)
                
                # êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì—…ë¡œë“œ
                drive_url = None
                if self.use_google_drive and self.drive_service:
                    drive_url = self._upload_to_google_drive(image_data, index, prompt)
                
                logger.info(f"âœ… Hugging Face ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ: {local_path}")
                
                return {
                    "index": index,
                    "alt": prompt,
                    "local_path": str(local_path),
                    "url": drive_url or str(local_path),
                    "huggingface_model": HUGGINGFACE_MODEL
                }
                
            except requests.exceptions.Timeout:
                logger.warning(f"íƒ€ì„ì•„ì›ƒ ë°œìƒ (ì‹œë„ {attempt + 1}/{max_retries})")
                if attempt == max_retries - 1:
                    raise Exception("Hugging Face API íƒ€ì„ì•„ì›ƒ")
                time.sleep(5)
                
            except Exception as e:
                logger.error(f"Hugging Face API ì—ëŸ¬: {e}")
                if attempt == max_retries - 1:
                    raise Exception(f"Hugging Face ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}")
                time.sleep(3)

    def _save_image_locally(self, image_data: bytes, index: int) -> Path:
        """
        ì´ë¯¸ì§€ë¥¼ ë¡œì»¬ì— ì €ì¥ (ì¹´í…Œê³ ë¦¬ë³„ í´ë”)

        Args:
            image_data: ì´ë¯¸ì§€ ë°”ì´ë„ˆë¦¬ ë°ì´í„°
            index: ì´ë¯¸ì§€ ì¸ë±ìŠ¤

        Returns:
            ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
        """
        # ì¹´í…Œê³ ë¦¬ë³„ í´ë” ìƒì„±
        if self.category:
            save_dir = IMAGES_DIR / self.category
        else:
            save_dir = IMAGES_DIR
        save_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = save_dir / f"image_{timestamp}_{index}.png"

        with open(filename, 'wb') as f:
            f.write(image_data)

        logger.info(f"ì´ë¯¸ì§€ ë¡œì»¬ ì €ì¥: {filename} (ì¹´í…Œê³ ë¦¬: {self.category or 'ì—†ìŒ'})")
        return filename

    def _upload_to_google_drive(self, image_data: bytes, index: int, description: str) -> Optional[str]:
        """
        ì´ë¯¸ì§€ë¥¼ êµ¬ê¸€ ë“œë¼ì´ë¸Œì— ì—…ë¡œë“œ

        Args:
            image_data: ì´ë¯¸ì§€ ë°”ì´ë„ˆë¦¬
            index: ì¸ë±ìŠ¤
            description: ì„¤ëª…

        Returns:
            ê³µìœ  ê°€ëŠ¥í•œ URL
        """
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"image_{timestamp}_{index}.png"

            file_metadata = {
                'name': filename,
                'description': description,
                'parents': [GOOGLE_DRIVE_FOLDER_ID] if GOOGLE_DRIVE_FOLDER_ID else []
            }

            media = MediaIoBaseUpload(
                BytesIO(image_data),
                mimetype='image/png',
                resumable=True
            )

            file = self.drive_service.files().create(
                body=file_metadata,
                media_body=media,
                fields='id, webViewLink, webContentLink'
            ).execute()

            # íŒŒì¼ ê³µìœ  ì„¤ì • (ëˆ„êµ¬ë‚˜ ë³¼ ìˆ˜ ìˆë„ë¡)
            self.drive_service.permissions().create(
                fileId=file['id'],
                body={'type': 'anyone', 'role': 'reader'}
            ).execute()

            # ì§ì ‘ ì ‘ê·¼ ê°€ëŠ¥í•œ URL ìƒì„±
            file_id = file['id']
            direct_url = f"https://drive.google.com/uc?export=view&id={file_id}"

            logger.info(f"êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì—…ë¡œë“œ ì™„ë£Œ: {direct_url}")
            return direct_url

        except Exception as e:
            logger.error(f"êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    generator = ImageGenerator(use_google_drive=False)

    # ìƒ˜í”Œ í”Œë ˆì´ìŠ¤í™€ë”
    sample_placeholders = [
        {
            "index": 0,
            "alt": "[ì´ë¯¸ì§€ ì„¤ëª…: ë¯¸ë˜ì ì¸ AI ë¡œë´‡ì´ ë„ì‹œë¥¼ ë°”ë¼ë³´ëŠ” ì¥ë©´]",
            "tag": "<img src='PLACEHOLDER' alt='...'>"
        },
        {
            "index": 1,
            "alt": "[ì´ë¯¸ì§€ ì„¤ëª…: ë°ì´í„° ë¶„ì„ ëŒ€ì‹œë³´ë“œë¥¼ ë³´ëŠ” ë¹„ì¦ˆë‹ˆìŠ¤ íŒ€]",
            "tag": "<img src='PLACEHOLDER' alt='...'>"
        }
    ]

    # ì´ë¯¸ì§€ ìƒì„±
    results = generator.generate_images(sample_placeholders)

    print("\nìƒì„±ëœ ì´ë¯¸ì§€:")
    for result in results:
        if result.get('url'):
            print(f"{result['index'] + 1}. {result['alt'][:50]}...")
            print(f"   ë¡œì»¬: {result['local_path']}")
            print(f"   URL: {result['url']}")
        else:
            print(f"{result['index'] + 1}. ì‹¤íŒ¨: {result.get('error')}")
